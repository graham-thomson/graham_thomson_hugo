<!doctype html>
<html>
<head>
    <base href="/">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta name="author" content="">

<meta name="description" content="">

<title>Using Scala UDFs in PySpark</title>
<meta name="generator" content="Hugo 0.69.1" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/styles/pojoaque.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700" rel="stylesheet" type="text/css">
<link  href="http://grahamflemingthomson.com/css/theme.min.css" rel="stylesheet" type="text/css">

</head>
<body>
<div class="page-container container-fluid">
<div class="col-md-3 menu">
    <nav class="col-md-3">
    
    <h3 class="home-link"><a href="http://grahamflemingthomson.com">Root</a></h3>
    <div id="last-posts" class="open">
        <h3 data-open="last-posts">Graham Thomson - Most recent posts</h3>
        <ul>
            
            <li><a href="http://grahamflemingthomson.com/covid19/">Plotting COVID-19 Cases in the US</a></li>
            
            <li><a href="http://grahamflemingthomson.com/scala_udfs/">Using Scala UDFs in PySpark</a></li>
            
            <li><a href="http://grahamflemingthomson.com/list-of-lists/">List of Lists</a></li>
            
            <li><a href="http://grahamflemingthomson.com/spark-s3a/">Spark &#43; s3a:// = ❤️</a></li>
            
            <li><a href="http://grahamflemingthomson.com/cosine-similarity-spark/">Cosine Similarity Spark</a></li>
            
            <li><a href="http://grahamflemingthomson.com/resume/">Resume</a></li>
            
        </ul>
    </div>
    

    
    <div id="tags" class="open">
        <h3 data-open="tags">Tags</h3>
        <ul class="tags">
            
            <li><a href="/tags/apache">apache</a></li>
            
            <li><a href="/tags/blog">blog</a></li>
            
            <li><a href="/tags/data-science">data-science</a></li>
            
            <li><a href="/tags/python">python</a></li>
            
            <li><a href="/tags/resume">resume</a></li>
            
            <li><a href="/tags/spark">spark</a></li>
            
        </ul>
    </div>
    

    
</nav>

</div>
<div class="col-md-9 content">

<h1>Using Scala UDFs in PySpark</h1>
<h4>Published 10-14-2019 14:18:21</h4>
<link href="http://grahamflemingthomson.com/css/share.css" rel="stylesheet" type="text/css">


<a class="resp-sharing-button__link" href="mailto:grahamflemingthomson@gmail.com?subject=Hello, Graham" target="_self" rel="noopener" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 4H2C.9 4 0 4.9 0 6v12c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17 0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1 0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08 0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://www.linkedin.com/shareArticle?mini=false&amp;url=http%3a%2f%2fgrahamflemingthomson.com%2fscala_udfs%2f&amp;source=http%3a%2f%2fgrahamflemingthomson.com%2fscala_udfs%2f" target="_blank" rel="noopener" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"/></svg>
    </div>
  </div>
</a>

<article>
    <p>It is often required to write UDFs in Python to extend Sparks native functionality, especially when it comes to Spark&rsquo;s <a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.linalg.Vectors">Vector objects</a> (the required data structure for feeding data to Spark&rsquo;s Machine Learning library).</p>
<p>However, because of the serialization that must take place passing Python objects to the JVM and back, Python UDFs in Spark are inherently slow. To minimize the compute time when using UDFs it often much faster to write the UDF in Scala and call it from Python.</p>
<p>Let&rsquo;s consider a dataframe that contains the following feature vectors and we want to apply a log transformation to.</p>
<pre><code>+-----------------------------------------------------------+
| count_features                                            |
+-----------------------------------------------------------+
|[148.03, 12.09, 38.2, 23.16, 58.79, 57.69, 38.1, 244.06]   |
|[71.86, 103.66, 158.05, 181.19, 32.17, 82.38, 10.06, 61.67]|
+-----------------------------------------------------------+
</code></pre><h3 id="the-python-udf-way">The Python UDF Way</h3>
<p>First, let&rsquo;s take a look at how we might solve this using just Python + PySpark.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> pyspark.ml.linalg <span style="color:#f92672">import</span> Vectors, VectorUDT
<span style="color:#f92672">import</span> pyspark.sql.functions <span style="color:#f92672">as</span> F

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">np_to_sparse</span>(np_array):
	<span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">	Helper function to convert a numpy.ndarray to a pyspark.ml.linalg.SparseVector.
</span><span style="color:#e6db74">	:param np_array: Numpy Array.
</span><span style="color:#e6db74">	:return: PySpark Sparse Vector.
</span><span style="color:#e6db74">	&#34;&#34;&#34;</span>
	non_zero_indices <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>nonzero(np_array)
	<span style="color:#66d9ef">return</span> Vectors<span style="color:#f92672">.</span>sparse(np_array<span style="color:#f92672">.</span>size, non_zero_indices[<span style="color:#ae81ff">0</span>], np_array[non_zero_indices])
    
<span style="color:#a6e22e">@F.udf</span>(returnType<span style="color:#f92672">=</span>VectorUDT())
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">log_features_python_sparse</span>(feature_vector):
	<span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">	PySpark UDF to apply a Log + 1 (to avoid -inf for 0.0 values) transformation to a PySpark vector.
</span><span style="color:#e6db74">	:param feature_vector: PySpark Vector (dense/sparse).
</span><span style="color:#e6db74">	:return: Log + 1 transformed PySpark Sparse Vector.
</span><span style="color:#e6db74">	&#34;&#34;&#34;</span>
	log_array <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log(feature_vector<span style="color:#f92672">.</span>toArray() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, dtype<span style="color:#f92672">=</span>float)
	<span style="color:#66d9ef">return</span> np_to_sparse(log_array)
	
df <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>select(log_features_python_sparse(<span style="color:#e6db74">&#34;features&#34;</span>)<span style="color:#f92672">.</span>alias(<span style="color:#e6db74">&#34;log_features&#34;</span>))
df<span style="color:#f92672">.</span>show(<span style="color:#ae81ff">2</span>)

<span style="color:#f92672">+----------------------------------------------+</span>
<span style="color:#f92672">|</span> log_features                                 <span style="color:#f92672">|</span>
<span style="color:#f92672">+----------------------------------------------+</span>
<span style="color:#f92672">|</span>[<span style="color:#ae81ff">5.0</span>, <span style="color:#ae81ff">2.57</span>, <span style="color:#ae81ff">3.67</span>, <span style="color:#ae81ff">3.18</span>, <span style="color:#ae81ff">4.09</span>, <span style="color:#ae81ff">4.07</span>, <span style="color:#ae81ff">3.67</span>, <span style="color:#ae81ff">5.5</span>]<span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>[<span style="color:#ae81ff">4.29</span>, <span style="color:#ae81ff">4.65</span>, <span style="color:#ae81ff">5.07</span>, <span style="color:#ae81ff">5.21</span>, <span style="color:#ae81ff">3.5</span>, <span style="color:#ae81ff">4.42</span>, <span style="color:#ae81ff">2.4</span>, <span style="color:#ae81ff">4.14</span>]<span style="color:#f92672">|</span>
<span style="color:#f92672">+----------------------------------------------+</span>
</code></pre></div><h3 id="the-scala-udf-way">The Scala UDF Way</h3>
<p>Now, let&rsquo;s write the Scala code to do the same transformation. We&rsquo;ll need a function that takes a Spark Vector, applies the same log + 1 transformation to each element and returns it as an (sparse) Vector.</p>
<p>We&rsquo;ll also define a function to register our new Scala UDF for use in Spark SQL.</p>
<pre><code>import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.linalg.{Vector, Vectors}
import org.apache.spark.sql.functions.udf
import org.apache.spark.sql.expressions.UserDefinedFunction
import math.log

object FeatureUDFs {

	def logFeatures(a: Vector): Vector = {
	    Vectors.dense(a.toArray.map(x =&gt; log(x + 1.0))).toSparse
	  }
	  
  	def logFeaturesUDF: UserDefinedFunction = udf(logFeatures _ )
	  
  	def registerUdf: UserDefinedFunction = {
  		val spark = SparkSession.builder().getOrCreate()
  		spark.udf.register(&quot;logFeatures&quot;, (a: Vector) =&gt; logFeatures(a))
  }
	  
}
</code></pre><p>With our code written, we need to compile a <code>.jar</code> via our prefered build tool (I&rsquo;ve been using <a href="https://gradle.org/">Gradle</a>). Once built, copy the <code>.jar</code> to your <code>$SPARK_HOME/jars/</code> (e.g. <code>cp build/libs/spark-utils.jar $SPARK_HOME/jars/</code>). Now, let&rsquo;s access our Scala UDF from PySpark.</p>
<h3 id="access-via-sparksql-in-pyspark">Access via SparkSQL in PySpark</h3>
<p>The easiest way to access the Scala UDF from PySpark is via SparkSQL.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> pyspark.sql <span style="color:#f92672">import</span> SparkSession
spark <span style="color:#f92672">=</span> SparkSession<span style="color:#f92672">.</span>builder<span style="color:#f92672">.</span>getOrCreate()

<span style="color:#75715e"># calling our registerUdf function from PySpark </span>
spark<span style="color:#f92672">.</span>sparkContext<span style="color:#f92672">.</span>_jvm<span style="color:#f92672">.</span>FeatureUDFs<span style="color:#f92672">.</span>registerUdf()

<span style="color:#75715e"># then access via SparkSQL</span>
df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>sql(<span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">SELECT
</span><span style="color:#e6db74">    logFeatures(features) AS log_features
</span><span style="color:#e6db74">FROM
</span><span style="color:#e6db74">    df
</span><span style="color:#e6db74">&#34;&#34;&#34;</span>)
df<span style="color:#f92672">.</span>show(<span style="color:#ae81ff">2</span>)

<span style="color:#f92672">+----------------------------------------------+</span>
<span style="color:#f92672">|</span> log_features                                 <span style="color:#f92672">|</span>
<span style="color:#f92672">+----------------------------------------------+</span>
<span style="color:#f92672">|</span>[<span style="color:#ae81ff">5.0</span>, <span style="color:#ae81ff">2.57</span>, <span style="color:#ae81ff">3.67</span>, <span style="color:#ae81ff">3.18</span>, <span style="color:#ae81ff">4.09</span>, <span style="color:#ae81ff">4.07</span>, <span style="color:#ae81ff">3.67</span>, <span style="color:#ae81ff">5.5</span>]<span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>[<span style="color:#ae81ff">4.29</span>, <span style="color:#ae81ff">4.65</span>, <span style="color:#ae81ff">5.07</span>, <span style="color:#ae81ff">5.21</span>, <span style="color:#ae81ff">3.5</span>, <span style="color:#ae81ff">4.42</span>, <span style="color:#ae81ff">2.4</span>, <span style="color:#ae81ff">4.14</span>]<span style="color:#f92672">|</span>
<span style="color:#f92672">+----------------------------------------------+</span>
</code></pre></div><h3 id="access-via-pyspark-api">Access via PySpark API</h3>
<p>Accessing via the Python is a little bit more work as we need to convert Python Spark objects to Scala ones and vice a versa. Of course in production, we can build a simple, importable, Python API to all of our Scala UDFs as the collection starts to grow.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> pyspark.sql <span style="color:#f92672">import</span> SparkSession
<span style="color:#f92672">from</span> pyspark.sql.column <span style="color:#f92672">import</span> Column, _to_java_column, _to_seq 

spark <span style="color:#f92672">=</span> SparkSession<span style="color:#f92672">.</span>builder<span style="color:#f92672">.</span>getOrCreate()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">log_features_scala_udf</span>(feature_vector): 
    logFeaturesUDF <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>_jvm<span style="color:#f92672">.</span>FeatureUDF<span style="color:#f92672">.</span>logFeaturesUDF() 
    <span style="color:#66d9ef">return</span> Column(logFeaturesUDF<span style="color:#f92672">.</span>apply(_to_seq(spark<span style="color:#f92672">.</span>sparkContext, [feature_vector], _to_java_column)))

df <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>select(log_features_scala_udf(<span style="color:#e6db74">&#34;features&#34;</span>)<span style="color:#f92672">.</span>alias(<span style="color:#e6db74">&#34;log_features&#34;</span>))
df<span style="color:#f92672">.</span>show(<span style="color:#ae81ff">2</span>)

<span style="color:#f92672">+----------------------------------------------+</span>
<span style="color:#f92672">|</span> log_features                                 <span style="color:#f92672">|</span>
<span style="color:#f92672">+----------------------------------------------+</span>
<span style="color:#f92672">|</span>[<span style="color:#ae81ff">5.0</span>, <span style="color:#ae81ff">2.57</span>, <span style="color:#ae81ff">3.67</span>, <span style="color:#ae81ff">3.18</span>, <span style="color:#ae81ff">4.09</span>, <span style="color:#ae81ff">4.07</span>, <span style="color:#ae81ff">3.67</span>, <span style="color:#ae81ff">5.5</span>]<span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>[<span style="color:#ae81ff">4.29</span>, <span style="color:#ae81ff">4.65</span>, <span style="color:#ae81ff">5.07</span>, <span style="color:#ae81ff">5.21</span>, <span style="color:#ae81ff">3.5</span>, <span style="color:#ae81ff">4.42</span>, <span style="color:#ae81ff">2.4</span>, <span style="color:#ae81ff">4.14</span>]<span style="color:#f92672">|</span>
<span style="color:#f92672">+----------------------------------------------+</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3>
<p>On a week of one of our event tables that has ≈300 million observations and ≈400 features the Python UDF version took over 2.5x the wall time of the Scala UDF. On less efficient Python UDFs that do not use the relatively speedy numpy package, we&rsquo;ve seen 7-10x improvements in runtime using a Scala UDF!</p>

</article>



</div>
</div>
<script src="http://grahamflemingthomson.com/js/theme.min.js" type="text/javascript"></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-73249319-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


</body>
</html>

